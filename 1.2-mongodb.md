---
description: reading and writing from and to mongodb
---

# 1.2 MongoDB - NoSql

### **Dependencies**

```text
 <!-- https://mvnrepository.com/artifact/org.mongodb/mongo-java-driver -->
<dependency>
    <groupId>org.mongodb</groupId>
    <artifactId>mongo-java-driver</artifactId>
    <version>3.4.2</version>
</dependency>
  <!-- https://mvnrepository.com/artifact/org.mongodb.spark/mongo-spark-connector -->
<dependency>
    <groupId>org.mongodb.spark</groupId>
    <artifactId>mongo-spark-connector_2.11</artifactId>
    <version>2.4.1</version>
</dependency>
```

## Spark-Mongo-Configurations

```java
String inputMongonoAuth = "mongodb://"+host+":"+port+"/test.myCollection";
		 
		SparkSession spark = SparkSession.builder()
			      .master("local[*]")
			      .appName("MongoSparkConnectorIntro")
			      .config("spark.mongodb.input.uri", inputMongonoAuth)
			      .config("spark.mongodb.output.uri", inputMongonoAuth)
			      .getOrCreate();
		
	 
		JavaSparkContext jsc = new JavaSparkContext(spark.sparkContext());
```

## Get Data from given db and collection

```java
private static Dataset<Row> getDB(JavaSparkContext jsc_, String DB, String Coll1) {

		// Create a custom ReadConfig
		System.out.println("/****************** Reading Databas"+ DB + " and "+Coll1+"******************/");
		System.out.println("Reading Database "+ DB + " and "+Coll1);
		Map<String, String> readOverrides = new HashMap<String, String>();
		readOverrides.put("database",DB );
		readOverrides.put("collection", Coll1);
		readOverrides.put("readPreference.name", "secondaryPreferred");
		
		System.out.println(readOverrides);
		ReadConfig readConfig = ReadConfig.create(jsc_).withOptions(readOverrides);
		
		Dataset<Row> DS = MongoSpark.load(jsc_,readConfig).toDF().drop("_id").dropDuplicates();
		System.out.println();
		System.out.println("Printing first Record in "+Coll1);
		DS.show(1);
		System.out.println();
		System.out.println("/************************************/");
		
		  return DS;
		   
	}
```

## Save To Mongodb

```java
MongoSpark.save(ResCasted.dropDuplicates().na().fill("").write()
				.option("database", GoldenCopyDB)
				.option("collection",GoldenCopycoll).mode("overwrite"));

```

{% hint style="info" %}
```java
ResCasted.dropDuplicates().na().fill("") ,
 If value for a key has null then the key won't be going to store in DB,So that's why replaced na() to empty.
```
{% endhint %}





